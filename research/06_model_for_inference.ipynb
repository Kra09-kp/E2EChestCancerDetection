{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd956c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/kirti/Dev/DeepLearning/Project/E2E/ChestCancerDetection/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8c6c0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/kirti/Dev/DeepLearning/Project/E2E/ChestCancerDetection'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "%pwd    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fb3fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelInferenceConfig:\n",
    "    root_dir: Path\n",
    "    source_url: str\n",
    "    local_model_file: Path\n",
    "    model_dir: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff8ffd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories\n",
    "\n",
    "class ConfigManager:\n",
    "    def __init__(self, config_file_path=CONFIG_FILE_PATH, params_file_path=PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "        print(self.config.artifacts_root)\n",
    "        create_directories([self.config.artifacts_root]) \n",
    "    \n",
    "    def get_model_inference_config(self) -> ModelInferenceConfig:\n",
    "        config = self.config.model_inference\n",
    "        create_directories([config.root_dir])\n",
    "        return ModelInferenceConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            source_url=config.source_url,\n",
    "            local_model_file=config.local_model_file,\n",
    "            model_dir=config.model_dir\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c10f4179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import gdown\n",
    "from cnnClassifier import logger\n",
    "from cnnClassifier.utils.common import get_file_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1f6fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelInference:\n",
    "    def __init__(self,config: ModelInferenceConfig) -> None:\n",
    "        self.config = config\n",
    "\n",
    "    def download_model(self):\n",
    "        \n",
    "        '''\n",
    "        Downloads model from the source URL to the local data file path.\n",
    "        If the file already exists, it skips the download.\n",
    "        '''\n",
    "\n",
    "        try:\n",
    "            model_url = self.config.source_url\n",
    "            model_path = self.config.local_model_file\n",
    "            os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "            logger.info(f\"Downloading model from {model_url}\")\n",
    "\n",
    "            file_id = model_url.split('/')[-2]\n",
    "            prefix = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
    "            if os.path.exists(model_path):\n",
    "                file_size = get_file_size(Path(model_path))\n",
    "                if file_size > 0:\n",
    "                    logger.info(f\"File already exists at {model_path} with size {file_size} bytes. Skipping download.\")\n",
    "                    return\n",
    "            \n",
    "            gdown.download(prefix, model_path, quiet=False)\n",
    "\n",
    "            logger.info(f\"Downloaded data to {model_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.info(f\"Error downloading data: {e}\")\n",
    "            raise e\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6e5929c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifacts\n",
      "[2025-07-28 22:46:50,703|(INFO)| File: common | Message: Created directory: artifacts]\n",
      "[2025-07-28 22:46:50,729|(INFO)| File: common | Message: Created directory: artifacts/model_inference]\n",
      "[2025-07-28 22:46:50,745|(INFO)| File: 1374819729 | Message: Downloading model from https://drive.google.com/file/d/1wDxN-Fmsd3oGFJT2a__38iK_gtJfhFSo/view?usp=sharing]\n",
      "[2025-07-28 22:46:50,756|(INFO)| File: 1374819729 | Message: File already exists at artifacts/model_inference/model.pth with size 162722852 bytes. Skipping download.]\n",
      "[2025-07-28 22:46:50,777|(INFO)| File: 145245731 | Message: Model downloaded successfully.]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config_manager = ConfigManager()\n",
    "    data_ingestion_config = config_manager.get_model_inference_config()\n",
    "    data_ingestion = ModelInference(config=data_ingestion_config)\n",
    "\n",
    "    data_ingestion.download_model()\n",
    "    logger.info(\"Model downloaded successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error while downloading model : {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a55e7920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.models.vgg.VGG'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.load(data_ingestion_config.local_model_file,\n",
    "                   map_location=torch.device('cpu'),\n",
    "                   weights_only=False)\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39b9d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
