{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd2578d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/kirti/Dev/DeepLearning/Project/E2E/ChestCancerDetection/research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59e6c791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/kirti/Dev/DeepLearning/Project/E2E/ChestCancerDetection'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f16d2576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path    \n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareBaseModelConfig:\n",
    "    root_dir: Path\n",
    "    base_model_save_path: Path\n",
    "    update_base_model_path: Path\n",
    "    params_image_size: list\n",
    "    params_batch_size: int\n",
    "    params_epochs: int\n",
    "    params_classes: int\n",
    "    params_weights: str\n",
    "    params_learning_rate: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64f24fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6f53ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigManager:\n",
    "    def __init__(self, config_path: Path = CONFIG_FILE_PATH, \n",
    "                 params_path: Path = PARAMS_FILE_PATH):\n",
    "        \"\"\"        Initializes the ConfigManager with paths to the configuration and parameters files.\n",
    "        Args:\n",
    "            config_path (Path): Path to the configuration file.\n",
    "            params_path (Path): Path to the parameters file.\n",
    "        \"\"\"\n",
    "        self.config = read_yaml(config_path)\n",
    "        self.params = read_yaml(params_path)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_prepare_base_model_config(self) -> PrepareBaseModelConfig:\n",
    "\n",
    "        config = self.config.prepare_base_model\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "        prepare_base_model_config = PrepareBaseModelConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            base_model_save_path=Path(config.base_model_save_path),\n",
    "            update_base_model_path=Path(config.update_base_model_path),\n",
    "            params_image_size=self.params.IMAGE_SIZE,\n",
    "            params_batch_size=self.params.BATCH_SIZE,\n",
    "            params_epochs=self.params.EPOCHS,\n",
    "            params_classes=self.params.CLASSES,\n",
    "            params_weights=self.params.WEIGHTS,\n",
    "            params_learning_rate=self.params.LEARNING_RATE\n",
    "        )\n",
    "\n",
    "        return prepare_base_model_config\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d402d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "from torchvision.models import VGG16_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fe4ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareBaseModel:\n",
    "    def __init__(self, config: PrepareBaseModelConfig):\n",
    "        \"\"\"Initializes the PrepareBaseModel with the given configuration.\n",
    "        \n",
    "        Args:\n",
    "            config (PrepareBaseModelConfig): Configuration for preparing the base model.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "\n",
    "    def get_base_model(self):\n",
    "        \"\"\" Return vgg16 model with imagenet weights without top layer.\"\"\"\n",
    "        base_model = torchvision.models.vgg16(\n",
    "            weights=self.config.params_weights,\n",
    "            progress=True,  \n",
    "        )\n",
    "\n",
    "        # Remove the top layer (classifier)\n",
    "        base_model.classifier = nn.Sequential()\n",
    "\n",
    "        #save the base model\n",
    "        base_model_save_path = self.config.base_model_save_path\n",
    "        os.makedirs(base_model_save_path.parent,exist_ok=True)\n",
    "        self.save_model(base_model, base_model_save_path)\n",
    "        print(f\"Base model saved at: {base_model_save_path}\")\n",
    "\n",
    "\n",
    "    def update_base_model(self, freeze_all=True, freeze_till=None):\n",
    "        \"\"\"Updates the base model by modifying the classifier and setting up the optimizer.\n",
    "        \n",
    "        Args:\n",
    "            freeze_all (bool): Whether to freeze all layers.\n",
    "            freeze_till (int): Layer index till which to freeze.\n",
    "        \"\"\"\n",
    "        model = self._prepare_full_model(\n",
    "            model=self.config.base_model_save_path,\n",
    "            classes=self.config.params_classes,\n",
    "            freeze_all=freeze_all,\n",
    "            freeze_till=freeze_till,\n",
    "            learning_rate=self.config.params_learning_rate\n",
    "        )\n",
    "\n",
    "        # Print model summary\n",
    "        print(\"Model Summary:\")\n",
    "        summary(model, input_size=(3,224,224), batch_size=self.config.params_batch_size)\n",
    "        # Save the updated model\n",
    "        update_base_model_path = self.config.update_base_model_path\n",
    "        os.makedirs(update_base_model_path.parent, exist_ok=True)\n",
    "        self.save_model(model, update_base_model_path)\n",
    "        print(f\"Updated base model saved at: {update_base_model_path}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _prepare_full_model(model,classes,freeze_all,freeze_till,learning_rate):\n",
    "        \"\"\"Prepares the full model by modifying the classifier and setting up the optimizer.\n",
    "        \n",
    "        Args:\n",
    "            model (torch.nn.Module): The base model to modify.\n",
    "            classes (int): Number of output classes.\n",
    "            freeze_all (bool): Whether to freeze all layers.\n",
    "            freeze_till (int): Layer index till which to freeze.\n",
    "            learning_rate (float): Learning rate for the optimizer.\n",
    "        \n",
    "        Returns:\n",
    "            torch.nn.Module: The modified model with a new classifier.\n",
    "        \"\"\"\n",
    "\n",
    "        model = PrepareBaseModel.load_model(model_path=model)\n",
    "        if freeze_all:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        elif freeze_till is not None:\n",
    "            for param in list(model.parameters())[:freeze_till]:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # Modify the classifier\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(25088, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, classes)\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(model: torch.nn.Module, path: Path):\n",
    "        \"\"\"Saves the model to the specified path.\n",
    "        \n",
    "        Args:\n",
    "            model (torch.nn.Module): The model to save.\n",
    "            path (Path): The path where the model will be saved.\n",
    "        \"\"\"\n",
    "        torch.save(model.state_dict(), path)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(model_path: Path):\n",
    "        \"\"\"Loads the model from the specified path.\n",
    "        \n",
    "        Args:\n",
    "            model_path (Path): The path from which to load the model.\n",
    "        Returns:\n",
    "            torch.nn.Module: The loaded model.\n",
    "        \"\"\"\n",
    "        model = torchvision.models.vgg16(weights=None)\n",
    "        model.classifier = torch.nn.Sequential()\n",
    "        state_dict = torch.load(model_path)\n",
    "        model.load_state_dict(state_dict)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57d5ff0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-09 12:36:46,408|(INFO)| File: common | Message: Created directory: artifacts]\n",
      "[2025-07-09 12:36:46,428|(INFO)| File: common | Message: Created directory: artifacts/prepare_base_model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model saved at: artifacts/prepare_base_model/base_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8656/4086291215.py:110: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [16, 64, 224, 224]           1,792\n",
      "              ReLU-2         [16, 64, 224, 224]               0\n",
      "            Conv2d-3         [16, 64, 224, 224]          36,928\n",
      "              ReLU-4         [16, 64, 224, 224]               0\n",
      "         MaxPool2d-5         [16, 64, 112, 112]               0\n",
      "            Conv2d-6        [16, 128, 112, 112]          73,856\n",
      "              ReLU-7        [16, 128, 112, 112]               0\n",
      "            Conv2d-8        [16, 128, 112, 112]         147,584\n",
      "              ReLU-9        [16, 128, 112, 112]               0\n",
      "        MaxPool2d-10          [16, 128, 56, 56]               0\n",
      "           Conv2d-11          [16, 256, 56, 56]         295,168\n",
      "             ReLU-12          [16, 256, 56, 56]               0\n",
      "           Conv2d-13          [16, 256, 56, 56]         590,080\n",
      "             ReLU-14          [16, 256, 56, 56]               0\n",
      "           Conv2d-15          [16, 256, 56, 56]         590,080\n",
      "             ReLU-16          [16, 256, 56, 56]               0\n",
      "        MaxPool2d-17          [16, 256, 28, 28]               0\n",
      "           Conv2d-18          [16, 512, 28, 28]       1,180,160\n",
      "             ReLU-19          [16, 512, 28, 28]               0\n",
      "           Conv2d-20          [16, 512, 28, 28]       2,359,808\n",
      "             ReLU-21          [16, 512, 28, 28]               0\n",
      "           Conv2d-22          [16, 512, 28, 28]       2,359,808\n",
      "             ReLU-23          [16, 512, 28, 28]               0\n",
      "        MaxPool2d-24          [16, 512, 14, 14]               0\n",
      "           Conv2d-25          [16, 512, 14, 14]       2,359,808\n",
      "             ReLU-26          [16, 512, 14, 14]               0\n",
      "           Conv2d-27          [16, 512, 14, 14]       2,359,808\n",
      "             ReLU-28          [16, 512, 14, 14]               0\n",
      "           Conv2d-29          [16, 512, 14, 14]       2,359,808\n",
      "             ReLU-30          [16, 512, 14, 14]               0\n",
      "        MaxPool2d-31            [16, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-32            [16, 512, 7, 7]               0\n",
      "           Linear-33                 [16, 1024]      25,691,136\n",
      "             ReLU-34                 [16, 1024]               0\n",
      "          Dropout-35                 [16, 1024]               0\n",
      "           Linear-36                  [16, 256]         262,400\n",
      "             ReLU-37                  [16, 256]               0\n",
      "          Dropout-38                  [16, 256]               0\n",
      "           Linear-39                    [16, 4]           1,028\n",
      "================================================================\n",
      "Total params: 40,669,252\n",
      "Trainable params: 25,954,564\n",
      "Non-trainable params: 14,714,688\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 9.19\n",
      "Forward/backward pass size (MB): 3497.84\n",
      "Params size (MB): 155.14\n",
      "Estimated Total Size (MB): 3662.17\n",
      "----------------------------------------------------------------\n",
      "Updated base model saved at: artifacts/prepare_base_model/update_base_model.pth\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigManager()\n",
    "    prepare_base_model_config = config.get_prepare_base_model_config()\n",
    "    prepare_base_model = PrepareBaseModel(config=prepare_base_model_config)\n",
    "    prepare_base_model.get_base_model()\n",
    "    prepare_base_model.update_base_model(freeze_all=True)\n",
    "\n",
    "except Exception as e:  \n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8763bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
